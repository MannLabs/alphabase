{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scoring.ml_scoring_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class of ML Scoring Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from alphabase.scoring.feature_extraction_base import BaseFeatureExtractor\n",
    "from alphabase.scoring.fdr import (\n",
    "    calculate_fdr,\n",
    "    calculate_fdr_from_ref,\n",
    "    fdr_to_q_values,\n",
    "    fdr_from_ref,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two key modules in ML-based rescoring: feature extraction and rescoring algorithm. Here we designed these two modules as flexible as possible for future extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "The feature extractor is more important than the ML methods, so we designed a flexible architecture for feature extraction. As shown in `BaseFeatureExtractor`, a feature extractor inherited from `BaseFeatureExtractor` must re-implement `BaseFeatureExtractor.extract_features`, and tells the ML methods what are the extracted features by providing `BaseFeatureExtractor.feature_list`. \n",
    "\n",
    "For example, if we have two feature extractors, `AlphaPeptFE` and `AlphaPeptDeepFE`:\n",
    "\n",
    "```python\n",
    "class AlphaPeptFE(BaseFeatureExtractor):\n",
    "    def extract_features(self, psm_df):\n",
    "        psm_df['ap_f1'] = ...\n",
    "        self._feature_list.append('ap_f1')\n",
    "        psm_df['ap_f2'] = ...\n",
    "        self._feature_list.append('ap_f2')\n",
    "\n",
    "class AlphaPeptDeepFE(BaseFeatureExtractor):\n",
    "    def extract_features(self, psm_df):\n",
    "        psm_df['ad_f1'] = ...\n",
    "        self._feature_list.append('ad_f1')\n",
    "        psm_df['ad_f2'] = ...\n",
    "        self._feature_list.append('ad_f2')\n",
    "```\n",
    "\n",
    "We can easily design a new feature extractor which combines these two and more feature extractors:\n",
    "\n",
    "```python\n",
    "class CombFE(BaseFeatureExtractor):\n",
    "    def __init__(self):\n",
    "        self.fe_list = [AlphaPeptFE(),AlphaPeptDeepFE()]\n",
    "\n",
    "    def extract_features(self, psm_df):\n",
    "        for fe in self.fe_list:\n",
    "            fe.extract_features(psm_df)\n",
    "\n",
    "    @property\n",
    "    def feature_list(self):\n",
    "        f_set = set()\n",
    "        for fe in self.fe_list:\n",
    "            f_set.update(fe.feature_list)\n",
    "        return list(f_set)\n",
    "```\n",
    "\n",
    "This will be useful for rescoring with DL features, for instance, when AlphaPeptDeep is or is not installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescoring Algorithm\n",
    "\n",
    "The rescoring algorithm called `Percolator` (Kall et al. 2007) based on the semi-supervised learning algorithm is still the most widely used in MS-based proteomics. Therefore, we used `Percolator` as the base rescoring class and others can re-implement its methods for different algorithms.  as well as different \n",
    "\n",
    "1. Rescoring algorithm. We have provided the base rescoring code structure in `Percolator`. If we are going to support DiaNN's brute-force supervised learning methods, we can define the class like this:\n",
    "\n",
    "```python\n",
    "class DiaNNRescoring(Percolator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_fdr = 100000 # disable target filtration on FDR, which is the same as DiaNN but different from Percolator\n",
    "\n",
    "        self._ml_model.fit(\n",
    "            train_df[self.feature_list].values, \n",
    "            train_label\n",
    "        )\n",
    "    def rescore(self, psm_df):\n",
    "        # We don't need iteration anymore, but cross validation is still necessary\n",
    "        df = self._cv_score(df)\n",
    "        return self._estimate_fdr(df)\n",
    "```\n",
    "\n",
    "2. ML models. Personally, `Percolator` with a linear classifier (SVM or LogisticRegression) is prefered. But as a framework, we should support different ML models. We can easily switch to the random forest by `self.ml_model = RandomForestClassifier()`. We can also use a DL model which provides sklearn-like `fit()` and `decision_function()` APIs for rescoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Percolator:\n",
    "    def __init__(self):\n",
    "        self._feature_extractor:BaseFeatureExtractor = BaseFeatureExtractor()\n",
    "        self._ml_model = LogisticRegression()\n",
    "        \n",
    "        self.fdr_level = 'psm' # psm, precursor, peptide, or sequence\n",
    "        self.training_fdr = 0.01\n",
    "        self.per_raw_fdr = False\n",
    "\n",
    "        self.max_training_sample = 200000\n",
    "        self.min_training_sample = 100\n",
    "        self.cv_fold = 1\n",
    "        self.iter_num = 1\n",
    "\n",
    "        self._base_features = ['score','nAA','charge']\n",
    "\n",
    "    @property\n",
    "    def feature_list(self)->list:\n",
    "        \"\"\" Get extracted feature_list. Property, read-only \"\"\"\n",
    "        return list(set(\n",
    "            self._base_features+\n",
    "            self.feature_extractor.feature_list\n",
    "        ))\n",
    "\n",
    "    @property\n",
    "    def ml_model(self):\n",
    "        \"\"\" \n",
    "        ML model in Percolator.\n",
    "        It can be sklearn models or other models but implement \n",
    "        the methods `fit()` and `decision_function()` (or `predict_proba()`) \n",
    "        which are the same as sklearn models.\n",
    "        \"\"\"\n",
    "        return self._ml_model\n",
    "    \n",
    "    @ml_model.setter\n",
    "    def ml_model(self, model):\n",
    "        self._ml_model = model\n",
    "\n",
    "    @property\n",
    "    def feature_extractor(self)->BaseFeatureExtractor:\n",
    "        \"\"\"\n",
    "        The feature extractor inherited from `BaseFeatureExtractor`\n",
    "        \"\"\"\n",
    "        return self._feature_extractor\n",
    "    \n",
    "    @feature_extractor.setter\n",
    "    def feature_extractor(self, fe:BaseFeatureExtractor):\n",
    "        self._feature_extractor = fe\n",
    "\n",
    "    def extract_features(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "        *args, **kwargs\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract features for rescoring.\n",
    "\n",
    "        *args and **kwargs are used for \n",
    "        `self.feature_extractor.extract_features`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        psm_df : pd.DataFrame\n",
    "            PSM DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            psm_df with feature columns appended inplace.\n",
    "        \"\"\"\n",
    "        psm_df['ml_score'] = psm_df.score\n",
    "        psm_df = self._estimate_psm_fdr(psm_df)\n",
    "        return self._feature_extractor.extract_features(\n",
    "            psm_df, *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def rescore(self, \n",
    "        df:pd.DataFrame\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Estimate ML scores and then FDRs (q-values)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            psm_df\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            psm_df with `ml_score` and `fdr` columns updated inplace\n",
    "        \"\"\"\n",
    "        for i in range(self.iter_num):\n",
    "            df = self._cv_score(df)\n",
    "            df = self._estimate_fdr(df, 'psm', False)\n",
    "            df = self.feature_extractor.update_features(df)\n",
    "        df = self._estimate_fdr(df)\n",
    "        return df\n",
    "\n",
    "    def run_rerank_workflow(self,\n",
    "        top_k_psm_df:pd.DataFrame,\n",
    "        rerank_column:str='spec_idx',\n",
    "        *args, **kwargs\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run percolator workflow with reranking \n",
    "        the peptides for each spectrum.\n",
    "\n",
    "        - self.extract_features()\n",
    "        - self.rescore()\n",
    "\n",
    "        *args and **kwargs are used for \n",
    "        `self.feature_extractor.extract_features`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        top_k_psm_df : pd.DataFrame\n",
    "            PSM DataFrame\n",
    "\n",
    "        rerank_column : str\n",
    "            The column use to rerank PSMs. \n",
    "            \n",
    "            For example, use the following code to select \n",
    "            the top-ranked peptide for each spectrum.\n",
    "            ```\n",
    "            rerank_column = 'spec_idx' # scan_num\n",
    "            idx = top_k_psm_df.groupby(\n",
    "                ['raw_name',rerank_column]\n",
    "            )['ml_score'].idxmax()\n",
    "            psm_df = top_k_psm_df.loc[idx].copy()\n",
    "            ```\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Only top-scored PSM is returned for \n",
    "            each group of the `rerank_column`.\n",
    "        \"\"\"\n",
    "        top_k_psm_df = self.extract_features(\n",
    "            top_k_psm_df, *args, **kwargs\n",
    "        )\n",
    "        idxmax = top_k_psm_df.groupby(\n",
    "            ['raw_name',rerank_column]\n",
    "        )['ml_score'].idxmax()\n",
    "\n",
    "        df = top_k_psm_df.loc[idxmax].copy()\n",
    "        self._train_and_score(df)\n",
    "\n",
    "        top_k_psm_df = self._predict(top_k_psm_df)\n",
    "        idxmax = top_k_psm_df.groupby(\n",
    "            ['raw_name',rerank_column]\n",
    "        )['ml_score'].idxmax()\n",
    "        return top_k_psm_df.loc[idxmax].copy()\n",
    "\n",
    "    def run_rescore_workflow(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "        *args, **kwargs\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run percolator workflow:\n",
    "\n",
    "        - self.extract_features()\n",
    "        - self.rescore()\n",
    "\n",
    "        *args and **kwargs are used for \n",
    "        `self.feature_extractor.extract_features`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        psm_df : pd.DataFrame\n",
    "            PSM DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            psm_df with feature columns appended inplace.\n",
    "        \"\"\"\n",
    "        df = self.extract_features(\n",
    "            psm_df, *args, **kwargs\n",
    "        )\n",
    "        return self.rescore(df)\n",
    "\n",
    "    def _estimate_fdr_per_raw(self,\n",
    "        df:pd.DataFrame,\n",
    "        fdr_level:str\n",
    "    )->pd.DataFrame:\n",
    "        df_list = []\n",
    "        for raw_name, df_raw in df.groupby('raw_name'):\n",
    "            df_list.append(self._estimate_fdr(df_raw, \n",
    "                fdr_level = fdr_level,\n",
    "                per_raw_fdr = False\n",
    "            ))\n",
    "        return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    def _estimate_psm_fdr(self,\n",
    "        df:pd.DataFrame,\n",
    "    )->pd.DataFrame:\n",
    "        df = df.sort_values(\n",
    "            ['ml_score','decoy'], ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "        target_values = 1-df['decoy'].values\n",
    "        decoy_cumsum = np.cumsum(df['decoy'].values)\n",
    "        target_cumsum = np.cumsum(target_values)\n",
    "        fdr_values = decoy_cumsum/target_cumsum\n",
    "        df['fdr'] = fdr_to_q_values(fdr_values)\n",
    "        return df\n",
    "        \n",
    "    def _estimate_fdr(self, \n",
    "        df:pd.DataFrame,\n",
    "        fdr_level:str=None,\n",
    "        per_raw_fdr:bool=None,\n",
    "    )->pd.DataFrame:\n",
    "        if fdr_level is None: \n",
    "            fdr_level = self.fdr_level\n",
    "        if per_raw_fdr is None: \n",
    "            per_raw_fdr = self.per_raw_fdr\n",
    "\n",
    "        if per_raw_fdr:\n",
    "            return self._estimate_fdr_per_raw(\n",
    "                df, fdr_level=fdr_level\n",
    "            )\n",
    "\n",
    "        if fdr_level == 'psm':\n",
    "            return self._estimate_psm_fdr(df)\n",
    "        else:\n",
    "            if fdr_level == 'precursor':\n",
    "                _df = df.groupby([\n",
    "                    'sequence','mods','mod_sites','charge','decoy'\n",
    "                ])['ml_score'].max()\n",
    "            elif fdr_level == 'peptide':\n",
    "                _df = df.groupby([\n",
    "                    'sequence','mods','mod_sites','decoy'\n",
    "                ])['ml_score'].max()\n",
    "            else:\n",
    "                _df = df.groupby(['sequence','decoy'])['ml_score'].max()\n",
    "            _df = self._estimate_psm_fdr(_df)\n",
    "            df['fdr'] = fdr_from_ref(\n",
    "                df['ml_score'].values, _df['ml_score'].values, \n",
    "                _df['fdr'].values\n",
    "            )\n",
    "        return df\n",
    "\n",
    "    def _train(self, \n",
    "        train_t_df:pd.DataFrame, \n",
    "        train_d_df:pd.DataFrame\n",
    "    ):\n",
    "        train_t_df = train_t_df[train_t_df.fdr<=self.training_fdr]\n",
    "\n",
    "        if len(train_t_df) > self.max_training_sample:\n",
    "            train_t_df = train_t_df.sample(\n",
    "                n=self.max_training_sample, \n",
    "                random_state=1337\n",
    "            )\n",
    "        if len(train_d_df) > self.max_training_sample:\n",
    "            train_d_df = train_d_df.sample(\n",
    "                n=self.max_training_sample,\n",
    "                random_state=1337\n",
    "            )\n",
    "\n",
    "        train_df = pd.concat((train_t_df, train_d_df))\n",
    "        train_label = np.ones(len(train_df),dtype=np.int32)\n",
    "        train_label[len(train_t_df):] = 0\n",
    "\n",
    "        self._ml_model.fit(\n",
    "            train_df[self.feature_list].values, \n",
    "            train_label\n",
    "        )\n",
    "\n",
    "    def _predict(self, test_df):\n",
    "        try:\n",
    "            test_df['ml_score'] = self._ml_model.decision_function(\n",
    "                test_df[self.feature_list].values\n",
    "            )\n",
    "        except AttributeError:\n",
    "            test_df['ml_score'] = self._ml_model.predict_proba(\n",
    "                test_df[self.feature_list].values\n",
    "            )\n",
    "        return test_df\n",
    "\n",
    "    def _train_and_score(self,\n",
    "        df:pd.DataFrame\n",
    "    )->pd.DataFrame:\n",
    "\n",
    "        df_target = df[df.decoy == 0]\n",
    "        df_decoy = df[df.decoy != 0]\n",
    "\n",
    "        if (\n",
    "            np.sum(df_target.fdr<=self.training_fdr) < \n",
    "            self.min_training_sample or\n",
    "            len(df_decoy) < self.min_training_sample\n",
    "        ):\n",
    "            return df\n",
    "        \n",
    "        self._train(df_target, df_decoy)\n",
    "        test_df = pd.concat(\n",
    "            [df_target, df_decoy],\n",
    "            ignore_index=True\n",
    "        )\n",
    "    \n",
    "        return self._predict(test_df)\n",
    "\n",
    "    def _cv_score(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply cross-validation for rescoring.\n",
    "\n",
    "        It will split `df` into K folds. For each fold, \n",
    "        its ML scores are predicted by a model which \n",
    "        is trained by other K-1 folds .\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            PSMs to be rescored\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            PSMs after rescoring\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cv_fold <= 1:\n",
    "            return self._train_and_score(df)\n",
    "\n",
    "        df = df.sample(\n",
    "            frac=1, random_state=1337\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        df_target = df[df.decoy == 0]\n",
    "        df_decoy = df[df.decoy != 0]\n",
    "\n",
    "        if (\n",
    "            np.sum(df_target.fdr<=self.training_fdr) < \n",
    "            self.min_training_sample*self.cv_fold \n",
    "            or len(df_decoy) < \n",
    "            self.min_training_sample*self.cv_fold\n",
    "        ):\n",
    "            return df\n",
    "        \n",
    "        test_df_list = []\n",
    "        for i in range(self.cv_fold):\n",
    "            t_mask = np.ones(len(df_target), dtype=bool)\n",
    "            _slice = slice(i, len(df_target), self.cv_fold)\n",
    "            t_mask[_slice] = False\n",
    "            train_t_df = df_target[t_mask]\n",
    "            test_t_df = df_target[_slice]\n",
    "            \n",
    "            d_mask = np.ones(len(df_decoy), dtype=bool)\n",
    "            _slice = slice(i, len(df_decoy), self.cv_fold)\n",
    "            d_mask[_slice] = False\n",
    "            train_d_df = df_decoy[d_mask]\n",
    "            test_d_df = df_decoy[_slice]\n",
    "\n",
    "            self._train(train_t_df, train_d_df)\n",
    "\n",
    "            test_df = pd.concat((test_t_df, test_d_df))\n",
    "            test_df_list.append(self._predict(test_df))\n",
    "    \n",
    "        return pd.concat(test_df_list, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of `Percolator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.ml_model\n",
       "\n",
       ">      Percolator.ml_model ()\n",
       "\n",
       "ML model in Percolator.\n",
       "It can be sklearn models or other models but implement \n",
       "the methods `fit()` and `decision_function()` (or `predict_proba()`) \n",
       "which are the same as sklearn models."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.ml_model\n",
       "\n",
       ">      Percolator.ml_model ()\n",
       "\n",
       "ML model in Percolator.\n",
       "It can be sklearn models or other models but implement \n",
       "the methods `fit()` and `decision_function()` (or `predict_proba()`) \n",
       "which are the same as sklearn models."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L66){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_extractor\n",
       "\n",
       ">      Percolator.feature_extractor ()\n",
       "\n",
       "The feature extractor inherited from `BaseFeatureExtractor`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L66){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_extractor\n",
       "\n",
       ">      Percolator.feature_extractor ()\n",
       "\n",
       "The feature extractor inherited from `BaseFeatureExtractor`"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L37){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_list\n",
       "\n",
       ">      Percolator.feature_list ()\n",
       "\n",
       "Get extracted feature_list. Property, read-only"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L37){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_list\n",
       "\n",
       ">      Percolator.feature_list ()\n",
       "\n",
       "Get extracted feature_list. Property, read-only"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of `Percolator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L69){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.extract_features\n",
       "\n",
       ">      Percolator.extract_features (psm_df:pandas.core.frame.DataFrame, *args,\n",
       ">                                   **kwargs)\n",
       "\n",
       "Extract features for rescoring.\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L69){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.extract_features\n",
       "\n",
       ">      Percolator.extract_features (psm_df:pandas.core.frame.DataFrame, *args,\n",
       ">                                   **kwargs)\n",
       "\n",
       "Extract features for rescoring.\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L95){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.rescore\n",
       "\n",
       ">      Percolator.rescore (df:pandas.core.frame.DataFrame)\n",
       "\n",
       "Estimate ML scores and then FDRs (q-values)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| df | DataFrame | psm_df |\n",
       "| **Returns** | **DataFrame** | **psm_df with `ml_score` and `fdr` columns updated inplace** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L95){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.rescore\n",
       "\n",
       ">      Percolator.rescore (df:pandas.core.frame.DataFrame)\n",
       "\n",
       "Estimate ML scores and then FDRs (q-values)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| df | DataFrame | psm_df |\n",
       "| **Returns** | **DataFrame** | **psm_df with `ml_score` and `fdr` columns updated inplace** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.rescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L171){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rescore_workflow\n",
       "\n",
       ">      Percolator.run_rescore_workflow (psm_df:pandas.core.frame.DataFrame,\n",
       ">                                       *args, **kwargs)\n",
       "\n",
       "Run percolator workflow:\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L171){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rescore_workflow\n",
       "\n",
       ">      Percolator.run_rescore_workflow (psm_df:pandas.core.frame.DataFrame,\n",
       ">                                       *args, **kwargs)\n",
       "\n",
       "Run percolator workflow:\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.run_rescore_workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rerank_workflow\n",
       "\n",
       ">      Percolator.run_rerank_workflow (top_k_psm_df:pandas.core.frame.DataFrame,\n",
       ">                                      rerank_column:str='spec_idx', *args,\n",
       ">                                      **kwargs)\n",
       "\n",
       "Run percolator workflow with reranking \n",
       "the peptides for each spectrum.\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| top_k_psm_df | DataFrame |  | PSM DataFrame |\n",
       "| rerank_column | str | spec_idx | The column use to rerank PSMs. <br><br>For example, use the following code to select <br>the top-ranked peptide for each spectrum.<br>```<br>rerank_column = 'spec_idx' # scan_num<br>idx = top_k_psm_df.groupby(<br>    ['raw_name',rerank_column]<br>)['ml_score'].idxmax()<br>psm_df = top_k_psm_df.loc[idx].copy()<br>``` |\n",
       "| args |  |  |  |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rerank_workflow\n",
       "\n",
       ">      Percolator.run_rerank_workflow (top_k_psm_df:pandas.core.frame.DataFrame,\n",
       ">                                      rerank_column:str='spec_idx', *args,\n",
       ">                                      **kwargs)\n",
       "\n",
       "Run percolator workflow with reranking \n",
       "the peptides for each spectrum.\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| top_k_psm_df | DataFrame |  | PSM DataFrame |\n",
       "| rerank_column | str | spec_idx | The column use to rerank PSMs. <br><br>For example, use the following code to select <br>the top-ranked peptide for each spectrum.<br>```<br>rerank_column = 'spec_idx' # scan_num<br>idx = top_k_psm_df.groupby(<br>    ['raw_name',rerank_column]<br>)['ml_score'].idxmax()<br>psm_df = top_k_psm_df.loc[idx].copy()<br>``` |\n",
       "| args |  |  |  |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.run_rerank_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>nAA</th>\n",
       "      <th>charge</th>\n",
       "      <th>decoy</th>\n",
       "      <th>spec_idx</th>\n",
       "      <th>raw_name</th>\n",
       "      <th>ml_score</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.851979</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>raw</td>\n",
       "      <td>138.142766</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.746052</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>raw</td>\n",
       "      <td>133.867779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.415167</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>raw</td>\n",
       "      <td>133.447761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.857314</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>raw</td>\n",
       "      <td>131.877318</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.606208</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>raw</td>\n",
       "      <td>128.785713</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.346523</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.008649</td>\n",
       "      <td>0.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.703782</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.292748</td>\n",
       "      <td>0.989899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.058571</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.352293</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.901983</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.357704</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.320378</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>raw</td>\n",
       "      <td>-18.395421</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  nAA  charge  decoy  spec_idx raw_name    ml_score       fdr\n",
       "0    99.851979   26       3      0        18      raw  138.142766  0.000000\n",
       "1    98.746052    7       3      0        12      raw  133.867779  0.000000\n",
       "2    97.415167   16       2      0        16      raw  133.447761  0.000000\n",
       "3    96.857314   14       3      0        15      raw  131.877318  0.000000\n",
       "4    94.606208   17       3      0        48      raw  128.785713  0.000000\n",
       "..         ...  ...     ...    ...       ...      ...         ...       ...\n",
       "195   0.346523   18       2      1        89      raw  -17.008649  0.979798\n",
       "196   0.703782   15       3      1        82      raw  -17.292748  0.989899\n",
       "197   0.058571   22       3      1        77      raw  -17.352293  1.000000\n",
       "198   0.901983    9       2      1        64      raw  -17.357704  1.000000\n",
       "199   0.320378    8       2      0        31      raw  -18.395421  1.000000\n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'score': list(np.random.uniform(0,100,100))+list(np.random.uniform(0,10,100)),\n",
    "    'nAA': list(np.random.randint(7,30,200)),\n",
    "    'charge': list(np.random.randint(2,4,200)),\n",
    "    'decoy': [0]*100+[1]*100,\n",
    "    'spec_idx': np.repeat(np.arange(100),2),\n",
    "    'raw_name': 'raw',\n",
    "})\n",
    "perc = Percolator()\n",
    "perc.min_training_sample = 10\n",
    "perc.run_rescore_workflow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>nAA</th>\n",
       "      <th>charge</th>\n",
       "      <th>decoy</th>\n",
       "      <th>spec_idx</th>\n",
       "      <th>raw_name</th>\n",
       "      <th>ml_score</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>44.986000</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raw</td>\n",
       "      <td>23.239871</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94.020658</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>raw</td>\n",
       "      <td>61.762973</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>23.028068</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.346026</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79.163537</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>raw</td>\n",
       "      <td>50.584693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>61.673923</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>raw</td>\n",
       "      <td>36.500728</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2.306086</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>raw</td>\n",
       "      <td>-11.475920</td>\n",
       "      <td>0.744898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8.107192</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>raw</td>\n",
       "      <td>-6.765049</td>\n",
       "      <td>0.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9.717331</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>raw</td>\n",
       "      <td>-5.459666</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>4.381494</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>raw</td>\n",
       "      <td>-9.100027</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5.831152</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>raw</td>\n",
       "      <td>-8.040386</td>\n",
       "      <td>0.423913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  nAA  charge  decoy  spec_idx raw_name   ml_score       fdr\n",
       "54   44.986000   25       2      0         0      raw  23.239871  0.000000\n",
       "6    94.020658    7       3      0         1      raw  61.762973  0.000000\n",
       "73   23.028068   14       2      0         2      raw   5.346026  0.000000\n",
       "17   79.163537   28       3      0         3      raw  50.584693  0.000000\n",
       "36   61.673923   23       2      0         4      raw  36.500728  0.000000\n",
       "..         ...  ...     ...    ...       ...      ...        ...       ...\n",
       "170   2.306086    7       3      1        95      raw -11.475920  0.744898\n",
       "105   8.107192    8       2      1        96      raw  -6.765049  0.191011\n",
       "92    9.717331   10       3      1        97      raw  -5.459666  0.044944\n",
       "143   4.381494   29       3      1        98      raw  -9.100027  0.565217\n",
       "130   5.831152   26       3      1        99      raw  -8.040386  0.423913\n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc.run_rerank_workflow(df, rerank_column='spec_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
