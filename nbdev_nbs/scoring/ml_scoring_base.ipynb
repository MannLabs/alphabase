{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---#| default_exp scoring.ml_scoring_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class of ML Scoring Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphabase.scoring.ml_scoring_base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two key modules in ML-based rescoring: feature extraction and rescoring algorithm. Here we designed these two modules as flexible as possible for future extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "The feature extractor is more important than the ML methods, so we designed a flexible architecture for feature extraction. As shown in `BaseFeatureExtractor`, a feature extractor inherited from `BaseFeatureExtractor` must re-implement `BaseFeatureExtractor.extract_features`, and tells the ML methods what are the extracted features by providing `BaseFeatureExtractor.feature_list`. \n",
    "\n",
    "For example, if we have two feature extractors, `AlphaPeptFE` and `AlphaPeptDeepFE`:\n",
    "\n",
    "```python\n",
    "class AlphaPeptFE(BaseFeatureExtractor):\n",
    "    def extract_features(self, psm_df):\n",
    "        psm_df['ap_f1'] = ...\n",
    "        self._feature_list.append('ap_f1')\n",
    "        psm_df['ap_f2'] = ...\n",
    "        self._feature_list.append('ap_f2')\n",
    "\n",
    "class AlphaPeptDeepFE(BaseFeatureExtractor):\n",
    "    def extract_features(self, psm_df):\n",
    "        psm_df['ad_f1'] = ...\n",
    "        self._feature_list.append('ad_f1')\n",
    "        psm_df['ad_f2'] = ...\n",
    "        self._feature_list.append('ad_f2')\n",
    "```\n",
    "\n",
    "We can easily design a new feature extractor which combines these two and more feature extractors:\n",
    "\n",
    "```python\n",
    "class CombFE(BaseFeatureExtractor):\n",
    "    def __init__(self):\n",
    "        self.fe_list = [AlphaPeptFE(),AlphaPeptDeepFE()]\n",
    "\n",
    "    def extract_features(self, psm_df):\n",
    "        for fe in self.fe_list:\n",
    "            fe.extract_features(psm_df)\n",
    "\n",
    "    @property\n",
    "    def feature_list(self):\n",
    "        f_set = set()\n",
    "        for fe in self.fe_list:\n",
    "            f_set.update(fe.feature_list)\n",
    "        return list(f_set)\n",
    "```\n",
    "\n",
    "This will be useful for rescoring with DL features, for instance, when AlphaPeptDeep is or is not installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescoring Algorithm\n",
    "\n",
    "The rescoring algorithm called `Percolator` (Kall et al. 2007) based on the semi-supervised learning algorithm is still the most widely used in MS-based proteomics. Therefore, we used `Percolator` as the base rescoring class and others can re-implement its methods for different algorithms.  as well as different \n",
    "\n",
    "1. Rescoring algorithm. We have provided the base rescoring code structure in `Percolator`. If we are going to support DiaNN's brute-force supervised learning methods, we can define the class like this:\n",
    "\n",
    "```python\n",
    "class DiaNNRescoring(Percolator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_fdr = 100000 # disable target filtration on FDR, which is the same as DiaNN but different from Percolator\n",
    "\n",
    "        self._ml_model.fit(\n",
    "            train_df[self.feature_list].values, \n",
    "            train_label\n",
    "        )\n",
    "    def rescore(self, psm_df):\n",
    "        # We don't need iteration anymore, but cross validation is still necessary\n",
    "        df = self._cv_score(df)\n",
    "        return self._estimate_fdr(df)\n",
    "```\n",
    "\n",
    "2. ML models. Personally, `Percolator` with a linear classifier (SVM or LogisticRegression) is prefered. But as a framework, we should support different ML models. We can easily switch to the random forest by `self.ml_model = RandomForestClassifier()`. We can also use a DL model which provides sklearn-like `fit()` and `decision_function()` APIs for rescoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of `Percolator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.ml_model\n",
       "\n",
       ">      Percolator.ml_model ()\n",
       "\n",
       "ML model in Percolator.\n",
       "It can be sklearn models or other models but implement \n",
       "the methods `fit()` and `decision_function()` (or `predict_proba()`) \n",
       "which are the same as sklearn models."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.ml_model\n",
       "\n",
       ">      Percolator.ml_model ()\n",
       "\n",
       "ML model in Percolator.\n",
       "It can be sklearn models or other models but implement \n",
       "the methods `fit()` and `decision_function()` (or `predict_proba()`) \n",
       "which are the same as sklearn models."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L66){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_extractor\n",
       "\n",
       ">      Percolator.feature_extractor ()\n",
       "\n",
       "The feature extractor inherited from `BaseFeatureExtractor`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L66){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_extractor\n",
       "\n",
       ">      Percolator.feature_extractor ()\n",
       "\n",
       "The feature extractor inherited from `BaseFeatureExtractor`"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L37){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_list\n",
       "\n",
       ">      Percolator.feature_list ()\n",
       "\n",
       "Get extracted feature_list. Property, read-only"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L37){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.feature_list\n",
       "\n",
       ">      Percolator.feature_list ()\n",
       "\n",
       "Get extracted feature_list. Property, read-only"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of `Percolator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L69){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.extract_features\n",
       "\n",
       ">      Percolator.extract_features (psm_df:pandas.core.frame.DataFrame, *args,\n",
       ">                                   **kwargs)\n",
       "\n",
       "Extract features for rescoring.\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L69){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.extract_features\n",
       "\n",
       ">      Percolator.extract_features (psm_df:pandas.core.frame.DataFrame, *args,\n",
       ">                                   **kwargs)\n",
       "\n",
       "Extract features for rescoring.\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L95){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.rescore\n",
       "\n",
       ">      Percolator.rescore (df:pandas.core.frame.DataFrame)\n",
       "\n",
       "Estimate ML scores and then FDRs (q-values)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| df | DataFrame | psm_df |\n",
       "| **Returns** | **DataFrame** | **psm_df with `ml_score` and `fdr` columns updated inplace** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L95){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.rescore\n",
       "\n",
       ">      Percolator.rescore (df:pandas.core.frame.DataFrame)\n",
       "\n",
       "Estimate ML scores and then FDRs (q-values)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| df | DataFrame | psm_df |\n",
       "| **Returns** | **DataFrame** | **psm_df with `ml_score` and `fdr` columns updated inplace** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.rescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L171){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rescore_workflow\n",
       "\n",
       ">      Percolator.run_rescore_workflow (psm_df:pandas.core.frame.DataFrame,\n",
       ">                                       *args, **kwargs)\n",
       "\n",
       "Run percolator workflow:\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L171){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rescore_workflow\n",
       "\n",
       ">      Percolator.run_rescore_workflow (psm_df:pandas.core.frame.DataFrame,\n",
       ">                                       *args, **kwargs)\n",
       "\n",
       "Run percolator workflow:\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| psm_df | DataFrame | PSM DataFrame |\n",
       "| args |  |  |\n",
       "| kwargs |  |  |\n",
       "| **Returns** | **DataFrame** | **psm_df with feature columns appended inplace.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.run_rescore_workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rerank_workflow\n",
       "\n",
       ">      Percolator.run_rerank_workflow (top_k_psm_df:pandas.core.frame.DataFrame,\n",
       ">                                      rerank_column:str='spec_idx', *args,\n",
       ">                                      **kwargs)\n",
       "\n",
       "Run percolator workflow with reranking \n",
       "the peptides for each spectrum.\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| top_k_psm_df | DataFrame |  | PSM DataFrame |\n",
       "| rerank_column | str | spec_idx | The column use to rerank PSMs. <br><br>For example, use the following code to select <br>the top-ranked peptide for each spectrum.<br>```<br>rerank_column = 'spec_idx' # scan_num<br>idx = top_k_psm_df.groupby(<br>    ['raw_name',rerank_column]<br>)['ml_score'].idxmax()<br>psm_df = top_k_psm_df.loc[idx].copy()<br>``` |\n",
       "| args |  |  |  |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphabase/blob/main/alphabase/scoring/ml_scoring_base.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Percolator.run_rerank_workflow\n",
       "\n",
       ">      Percolator.run_rerank_workflow (top_k_psm_df:pandas.core.frame.DataFrame,\n",
       ">                                      rerank_column:str='spec_idx', *args,\n",
       ">                                      **kwargs)\n",
       "\n",
       "Run percolator workflow with reranking \n",
       "the peptides for each spectrum.\n",
       "\n",
       "- self.extract_features()\n",
       "- self.rescore()\n",
       "\n",
       "*args and **kwargs are used for \n",
       "`self.feature_extractor.extract_features`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| top_k_psm_df | DataFrame |  | PSM DataFrame |\n",
       "| rerank_column | str | spec_idx | The column use to rerank PSMs. <br><br>For example, use the following code to select <br>the top-ranked peptide for each spectrum.<br>```<br>rerank_column = 'spec_idx' # scan_num<br>idx = top_k_psm_df.groupby(<br>    ['raw_name',rerank_column]<br>)['ml_score'].idxmax()<br>psm_df = top_k_psm_df.loc[idx].copy()<br>``` |\n",
       "| args |  |  |  |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Percolator.run_rerank_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>nAA</th>\n",
       "      <th>charge</th>\n",
       "      <th>decoy</th>\n",
       "      <th>spec_idx</th>\n",
       "      <th>raw_name</th>\n",
       "      <th>ml_score</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.851979</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>raw</td>\n",
       "      <td>138.142766</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.746052</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>raw</td>\n",
       "      <td>133.867779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.415167</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>raw</td>\n",
       "      <td>133.447761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.857314</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>raw</td>\n",
       "      <td>131.877318</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.606208</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>raw</td>\n",
       "      <td>128.785713</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.346523</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.008649</td>\n",
       "      <td>0.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.703782</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.292748</td>\n",
       "      <td>0.989899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.058571</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.352293</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.901983</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>raw</td>\n",
       "      <td>-17.357704</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.320378</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>raw</td>\n",
       "      <td>-18.395421</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  nAA  charge  decoy  spec_idx raw_name    ml_score       fdr\n",
       "0    99.851979   26       3      0        18      raw  138.142766  0.000000\n",
       "1    98.746052    7       3      0        12      raw  133.867779  0.000000\n",
       "2    97.415167   16       2      0        16      raw  133.447761  0.000000\n",
       "3    96.857314   14       3      0        15      raw  131.877318  0.000000\n",
       "4    94.606208   17       3      0        48      raw  128.785713  0.000000\n",
       "..         ...  ...     ...    ...       ...      ...         ...       ...\n",
       "195   0.346523   18       2      1        89      raw  -17.008649  0.979798\n",
       "196   0.703782   15       3      1        82      raw  -17.292748  0.989899\n",
       "197   0.058571   22       3      1        77      raw  -17.352293  1.000000\n",
       "198   0.901983    9       2      1        64      raw  -17.357704  1.000000\n",
       "199   0.320378    8       2      0        31      raw  -18.395421  1.000000\n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'score': list(np.random.uniform(0,100,100))+list(np.random.uniform(0,10,100)),\n",
    "    'nAA': list(np.random.randint(7,30,200)),\n",
    "    'charge': list(np.random.randint(2,4,200)),\n",
    "    'decoy': [0]*100+[1]*100,\n",
    "    'spec_idx': np.repeat(np.arange(100),2),\n",
    "    'raw_name': 'raw',\n",
    "})\n",
    "perc = Percolator()\n",
    "perc.min_training_sample = 10\n",
    "perc.run_rescore_workflow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>nAA</th>\n",
       "      <th>charge</th>\n",
       "      <th>decoy</th>\n",
       "      <th>spec_idx</th>\n",
       "      <th>raw_name</th>\n",
       "      <th>ml_score</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>44.986000</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raw</td>\n",
       "      <td>23.239871</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94.020658</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>raw</td>\n",
       "      <td>61.762973</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>23.028068</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.346026</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79.163537</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>raw</td>\n",
       "      <td>50.584693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>61.673923</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>raw</td>\n",
       "      <td>36.500728</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2.306086</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>raw</td>\n",
       "      <td>-11.475920</td>\n",
       "      <td>0.744898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8.107192</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>raw</td>\n",
       "      <td>-6.765049</td>\n",
       "      <td>0.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9.717331</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>raw</td>\n",
       "      <td>-5.459666</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>4.381494</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>raw</td>\n",
       "      <td>-9.100027</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5.831152</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>raw</td>\n",
       "      <td>-8.040386</td>\n",
       "      <td>0.423913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  nAA  charge  decoy  spec_idx raw_name   ml_score       fdr\n",
       "54   44.986000   25       2      0         0      raw  23.239871  0.000000\n",
       "6    94.020658    7       3      0         1      raw  61.762973  0.000000\n",
       "73   23.028068   14       2      0         2      raw   5.346026  0.000000\n",
       "17   79.163537   28       3      0         3      raw  50.584693  0.000000\n",
       "36   61.673923   23       2      0         4      raw  36.500728  0.000000\n",
       "..         ...  ...     ...    ...       ...      ...        ...       ...\n",
       "170   2.306086    7       3      1        95      raw -11.475920  0.744898\n",
       "105   8.107192    8       2      1        96      raw  -6.765049  0.191011\n",
       "92    9.717331   10       3      1        97      raw  -5.459666  0.044944\n",
       "143   4.381494   29       3      1        98      raw  -9.100027  0.565217\n",
       "130   5.831152   26       3      1        99      raw  -8.040386  0.423913\n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc.run_rerank_workflow(df, rerank_column='spec_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
