{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp speclib.library_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "import alphabase.peptide.fragment as fragment\n",
    "from alphabase.io.hdf import HDF_File\n",
    "\n",
    "class SpecLibBase(object):\n",
    "    def __init__(self,\n",
    "        # e.g. ['b_1','b_2','y_1','y_2', ...]\n",
    "        charged_frag_types:typing.List[str], \n",
    "        min_frag_mz = 100, max_frag_mz = 2000,\n",
    "        min_precursor_mz = 400, max_precursor_mz = 6000,\n",
    "    ):\n",
    "        self.charged_frag_types = charged_frag_types\n",
    "        self._precursor_df:pd.DataFrame = None\n",
    "        self._fragment_inten_df:pd.DataFrame = None\n",
    "        self._fragment_mass_df:pd.DataFrame = None\n",
    "        self.min_frag_mz = min_frag_mz\n",
    "        self.max_frag_mz = max_frag_mz\n",
    "        self.min_precursor_mz = min_precursor_mz\n",
    "        self.max_precursor_mz = max_precursor_mz\n",
    "\n",
    "    @property\n",
    "    def precursor_df(self):\n",
    "        return self._precursor_df\n",
    "\n",
    "    @property\n",
    "    def fragment_mass_df(self):\n",
    "        return self._fragment_mass_df\n",
    "\n",
    "    @property\n",
    "    def fragment_inten_df(self):\n",
    "        return self._fragment_inten_df\n",
    "\n",
    "    def clip_precursor_by_mz_(self):\n",
    "        ''' \n",
    "        Clip self._precursor_df inplace\n",
    "        '''\n",
    "        self._precursor_df = self._precursor_df[\n",
    "            (self._precursor_df['precursor_mz']>=self.min_precursor_mz)&\n",
    "            (self._precursor_df['precursor_mz']<=self.max_precursor_mz)\n",
    "        ]\n",
    "        self._precursor_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def clip_inten_by_fragment_mass_(self):\n",
    "        ''' \n",
    "        Clip self._fragment_inten_df inplace. \n",
    "        All clipped intensities are set as zeros.\n",
    "        A more generic way is to use a mask.\n",
    "        '''\n",
    "        self._fragment_inten_df[\n",
    "            (self._fragment_mass_df<self.min_frag_mz)|\n",
    "            (self._fragment_mass_df>self.max_frag_mz)\n",
    "        ] = 0\n",
    "\n",
    "    def clip_inten_by_fragment_mass(self)->pd.DataFrame:\n",
    "        df = self._fragment_inten_df.copy()\n",
    "        df[\n",
    "            (self._fragment_mass_df<self.min_frag_mz)|\n",
    "            (self._fragment_mass_df>self.max_frag_mz)\n",
    "        ] = 0\n",
    "        return df\n",
    "    \n",
    "    def load_precursor_df(self, \n",
    "        precursor_files, **kwargs\n",
    "    ):\n",
    "        self._load_precursor_df(precursor_files, **kwargs)\n",
    "        self.clip_precursor_by_mz_()\n",
    "\n",
    "    def _load_precursor_df(self, precursor_files, **kwargs):\n",
    "        '''\n",
    "        All sub-class must reimplement this method\n",
    "        '''\n",
    "        raise NotImplementedError(\n",
    "            f'Sub-class of \"{self.__class__}\" must re-implement \"_load_precursor_df()\"'\n",
    "        )\n",
    "\n",
    "    def load_fragment_df(self, **kwargs):\n",
    "        self.load_fragment_mass_df(**kwargs)\n",
    "        self.load_fragment_inten_df(**kwargs)\n",
    "\n",
    "    def flatten_fragment_data(\n",
    "        self\n",
    "    )->typing.Tuple[np.array, np.array]:\n",
    "        '''\n",
    "        Create flattened (1-D) np.array for mass and intensity \n",
    "        dataframes, respectively. The arrays are references to \n",
    "        original data, that means: \n",
    "          1. This method is fast; \n",
    "          2. Changing the array values will change the df values. \n",
    "        They can be unraveled back using:\n",
    "          `array.reshape(len(self._fragment_mass_df.columns), -1)`\n",
    "\n",
    "        Retruns:\n",
    "            np.array: 1-D flattened mass array (a reference to \n",
    "            original mass df data)\n",
    "            np.array: 1-D flattened intensity array (a reference to \n",
    "            original intensity df data)\n",
    "        '''\n",
    "        return (\n",
    "            self._fragment_mass_df.values.reshape(-1),\n",
    "            self._fragment_inten_df.values.reshape(-1)\n",
    "        )\n",
    "\n",
    "    def load_fragment_inten_df(self, **kwargs):\n",
    "        '''\n",
    "        All sub-class must re-implement this method. \n",
    "        Fragment intensities can be predicted or from AlphaPept, or ...\n",
    "        '''\n",
    "        raise NotImplementedError(\n",
    "            f'Sub-class of \"{self.__class__}\" must re-implement \"load_fragment_inten_df()\"'\n",
    "        )\n",
    "\n",
    "    def load_fragment_mass_df(self):\n",
    "        need_clip = (\n",
    "            False if \n",
    "            'precursor_mz' in self._precursor_df.columns \n",
    "            else True\n",
    "        )\n",
    "\n",
    "        (\n",
    "            self._precursor_df, self._fragment_mass_df\n",
    "        ) = fragment.get_fragment_mass_dataframe(\n",
    "            self._precursor_df, self.charged_frag_types\n",
    "        )\n",
    "        if need_clip: self.clip_precursor_by_mz_()\n",
    "\n",
    "    def save_hdf(self, hdf_file):\n",
    "        _hdf = HDF_File(\n",
    "            hdf_file, \n",
    "            read_only=False, \n",
    "            truncate=True,\n",
    "            delete_existing=True\n",
    "        )\n",
    "        _hdf.precursor_df = self._precursor_df\n",
    "        _hdf.fragment_mass_df = self._fragment_mass_df\n",
    "        _hdf.fragment_inten_df = self._fragment_inten_df\n",
    "\n",
    "    def load_hdf(self, hdf_file):\n",
    "        self._hdf = HDF_File(\n",
    "            hdf_file,\n",
    "        )\n",
    "        self._precursor_df = self._hdf.precursor_df.values\n",
    "        self._fragment_mass_df = self._hdf.fragment_mass_df.values\n",
    "        self._fragment_inten_df = self._hdf.fragment_inten_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
