{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T12:56:30.176364Z",
     "start_time": "2021-10-26T12:56:30.150069Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module provides a common interface to access HDF files. It can be imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T12:56:33.872547Z",
     "start_time": "2021-10-26T12:56:33.074153Z"
    }
   },
   "outputs": [],
   "source": [
    "import alphabase.io.hdf\n",
    "\n",
    "# Other packages used to demonstrate functionality\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of relying directly on the `h5py` interface, we will use an HDF wrapper file to provide consistent access to only those specific HDF features we want. Since components of an HDF file come in three shapes `datasets`, `groups` and `attributes`, we will first define a generic HDF wrapper object to handle these components. Once this is done, the HDF wrapper file can be treated as such an object with additional features to open and close the initial connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T12:58:08.475874Z",
     "start_time": "2021-10-26T12:58:08.413143Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "import tempfile\n",
    "TEMPDIR = tempfile.gettempdir()\n",
    "\n",
    "def test_HDF_creation():\n",
    "    hdf_file_name = os.path.join(TEMPDIR, \"sandbox.hdf\")\n",
    "    hdf_file = alphabase.io.hdf.HDF_File(\n",
    "        hdf_file_name,\n",
    "        read_only=False,\n",
    "        truncate=True,\n",
    "        delete_existing=True\n",
    "    )\n",
    "    np.testing.assert_equal(len(hdf_file), 0)\n",
    "    file_size = os.path.getsize(hdf_file_name)\n",
    "    hdf_file.attr1 = 1\n",
    "    np.testing.assert_equal(hdf_file.attr1, 1)\n",
    "    file_size, old_file_size = os.path.getsize(hdf_file_name), file_size\n",
    "    assert file_size > old_file_size, \"Filesize not increased\"\n",
    "    array = np.random.rand(10)\n",
    "    hdf_file.array = array\n",
    "    np.testing.assert_equal(array, hdf_file.array.values)\n",
    "    np.testing.assert_equal(array[:3], hdf_file.array[:3])\n",
    "    np.testing.assert_equal((10,), hdf_file.array.shape)\n",
    "    file_size, old_file_size = os.path.getsize(hdf_file_name), file_size\n",
    "    assert file_size > old_file_size, \"Filesize not increased\"\n",
    "    hdf_file.array.array_attr = \"some attr\"\n",
    "    np.testing.assert_equal(hdf_file.array.array_attr, \"some attr\")\n",
    "    file_size, old_file_size = os.path.getsize(hdf_file_name), file_size\n",
    "    assert file_size > old_file_size, \"Filesize not increased\"\n",
    "    group = {\n",
    "        \"subgroup1\": {\n",
    "            \"subsubgroup\": {},\n",
    "            \"same_array\": array,\n",
    "            \"a_bool\": True\n",
    "        },\n",
    "        \"subgroup2\": {}\n",
    "    }\n",
    "    hdf_file.group = group\n",
    "    file_size, old_file_size = os.path.getsize(hdf_file_name), file_size\n",
    "    assert file_size > old_file_size, \"Filesize not increased\"\n",
    "    np.testing.assert_equal(hdf_file.group.subgroup1.a_bool, True)\n",
    "    np.testing.assert_equal(len(hdf_file.group.subgroup1), 2)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"col2\": np.arange(3),\n",
    "            \"col_str\": [\"str\", \"i\", \"ngs\"],\n",
    "        }\n",
    "    )\n",
    "    hdf_file.df = df\n",
    "    file_size, old_file_size = os.path.getsize(hdf_file_name), file_size\n",
    "    assert file_size > old_file_size, \"Filesize not increased\"\n",
    "    assert hdf_file.df.values.equals(df)\n",
    "    \n",
    "test_HDF_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T13:04:09.305435Z",
     "start_time": "2021-10-26T13:04:09.257789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<alphabase.io.hdf.HDF_File at 0x7fe26a4692b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "def test_HDF_reading():\n",
    "    hdf_file_name = os.path.join(TEMPDIR, \"sandbox.hdf\")\n",
    "    hdf_file = alphabase.io.hdf.HDF_File(\n",
    "        hdf_file_name,\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"col2\": np.arange(3),\n",
    "            \"col_str\": [\"str\", \"i\", \"ngs\"],\n",
    "        }\n",
    "    )\n",
    "    assert hdf_file.df.values.equals(df)\n",
    "    \n",
    "test_HDF_reading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T13:03:04.656746Z",
     "start_time": "2021-10-26T13:03:04.614475Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T13:03:17.621394Z",
     "start_time": "2021-10-26T13:03:17.601656Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alphabase]",
   "language": "python",
   "name": "conda-env-alphabase-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
