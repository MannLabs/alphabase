# AUTOGENERATED! DO NOT EDIT! File to edit: nbdev_nbs/io/hdf.ipynb (unless otherwise specified).

__all__ = ['HDF_Object_Wrapper', 'HDF_File']

# Cell

import h5py
import numpy as np
import pandas as pd
import re
import os
import contextlib

# Cell

class HDF_Object_Wrapper(object):
    '''
    A generic class to access HDF components.
    '''

    @property
    def read_only(self):
        return self._read_only

    @property
    def truncate(self):
        return self._truncate

    @property
    def hdf_parent_file_name(self):
        return self._hdf_parent_file_name

    @property
    def hdf_parent_group_name(self):
        return self._hdf_parent_group_name

    @property
    def values(self):
        return self[...]

    @property
    def metadata(self):
        with h5py.File(self.hdf_parent_file_name, "r") as hdf_file:
            return dict(hdf_file[self.hdf_parent_group_name].attrs)

    @property
    def dtype(self):
        return self._dtype

    @property
    def shape(self):
        return self._shape

    def __init__(
        self,
        *,
        hdf_parent_file_name: str,
        hdf_parent_group_name: str,
        read_only: bool = True,
        truncate: bool = False,
    ):
        object.__setattr__(self, "_read_only", read_only)
        object.__setattr__(self, "_truncate", truncate)
        object.__setattr__(
            self,
            "_hdf_parent_file_name",
            hdf_parent_file_name
        )
        object.__setattr__(
            self,
            "_hdf_parent_group_name",
            hdf_parent_group_name
        )
        with h5py.File(self.hdf_parent_file_name, "r") as hdf_file:
            hdf_object = hdf_file[self.hdf_parent_group_name]
            for name, value in hdf_object.attrs.items():
                object.__setattr__(self, name, value)
            if isinstance(hdf_object, h5py.Dataset):
                object.__setattr__(self, "_dtype", hdf_object.dtype)
                object.__setattr__(self, "_shape", hdf_object.shape)
            else:
                for name in hdf_object:
                    subobject = HDF_Object_Wrapper(
                        hdf_parent_file_name=self.hdf_parent_file_name,
                        hdf_parent_group_name=f"{self.hdf_parent_group_name}/{name}",
                        read_only=self.read_only,
                        truncate=self.truncate,
                    )
                    object.__setattr__(self, name, subobject)
                if "is_pd_dataframe" in hdf_object.attrs:
                    object.__setattr__(self, "_dtype", "dataframe")
                    object.__setattr__(
                        self,
                        "_shape",
                        (
                            subobject.shape,
                            len(hdf_object)
                        )
                    )
                else:
                    object.__setattr__(self, "_dtype", "group")
                    object.__setattr__(self, "_shape", len(hdf_object))

    def __iter__(self):
        with h5py.File(self.hdf_parent_file_name, "r") as hdf_file:
            hdf_object = hdf_file[self.hdf_parent_group_name]
            if isinstance(self.dtype, str):
                for name in hdf_object:
                    yield self.__getattribute__(name)
            else:
                for i in hdf_object:
                    yield i

    def __eq__(self, other):
        return (
            self.hdf_parent_file_name == other.self.hdf_parent_file_name
        ) and (
            self.hdf_parent_group_name == other.hdf_parent_group_name
        )

    def set_read_only(self, read_only: bool = True):
        object.__setattr__(self, "_read_only", read_only)
        if isinstance(self.dtype, str):
            for subset in self:
                subset.set_read_only(read_only)

    def set_truncate(self, truncate: bool = True):
        object.__setattr__(self, "_truncate", truncate)
        if isinstance(self.dtype, str):
            for subset in self:
                subset.set_truncate(truncate)


    @contextlib.contextmanager
    def modify(self, read_only=False, truncate=True):
        original_read_only = self.read_only
        original_truncate = self.truncate
        try:
            self.set_read_only(read_only)
            self.set_truncate(truncate)
            yield self
        finally:
            self.set_read_only(original_read_only)
            self.set_truncate(original_truncate)

    def __setattr__(self, name, value):
        if self.read_only:
            raise AttributeError("Cannot set read-only attributes")
        elif not isinstance(name, str):
            raise KeyError(f"Attribute name '{name}' is not a string")
        elif not bool(re.match(r'^[a-zA-Z_][\w.-]*$', name)):
            raise KeyError(f"Invalid attribute name: {name}")
        with h5py.File(self.hdf_parent_file_name, "a") as hdf_file:
            hdf_object = hdf_file[self.hdf_parent_group_name]
            exists = (name in hdf_object) or (name in hdf_object.attrs)
            if exists:
                if not self.truncate:
                    raise KeyError(
                        f"Attribute name '{name}' cannot be truncated"
                    )
            if isinstance(value, (str, bool, int, float)):
                hdf_object.attrs[name] = value
                parsed_value = value
            elif isinstance(value, (np.ndarray, pd.core.series.Series)):
                parsed_value = self.__create_new_dataset(
                    name,
                    value,
                    hdf_object,
                    exists,
                )
            elif isinstance(value, (dict, pd.DataFrame)):
                parsed_value = self.__create_new_group(
                    name,
                    value,
                    hdf_object,
                    exists,
                )
            else:
                raise NotImplementedError(f"Invalid attribute value {value}")
            object.__setattr__(self, name, parsed_value)

    def __create_new_dataset(
        self,
        name:str,
        array: np.ndarray,
        hdf_object: h5py.Group,
        exists: bool,
    ):
        if exists:
            del hdf_object[name]
        if isinstance(array, (pd.core.series.Series)):
            array = array.values
        hdf_dataset = hdf_object.create_dataset(
            name,
            data=array,
#             TODO
            compression="lzf",
#             # compression="gzip" if compress else None, # TODO slower to make, faster to load?
            shuffle=True,
            chunks=True,
            maxshape=tuple([None for i in array.shape]),
        )
        new_array = HDF_Object_Wrapper(
            hdf_parent_file_name=self.hdf_parent_file_name,
            hdf_parent_group_name=f"{self.hdf_parent_group_name}/{name}",
            read_only=self.read_only,
            truncate=self.truncate,
        )
        object.__setattr__(self, "_shape", self._shape + 1)
        return new_array

    def __create_new_group(
        self,
        name:str,
        new_dict: dict,
        hdf_object: h5py.Group,
        exists: bool,
    ):
        if exists:
            del hdf_object[name]
        new_group = hdf_object.create_group(name)
        if isinstance(new_dict, pd.DataFrame):
            new_dict = dict(new_dict)
            new_dict["is_pd_dataframe"] = True
            is_pd_dataframe = True
        else:
            is_pd_dataframe = False
        new_group = HDF_Object_Wrapper(
            hdf_parent_file_name=self.hdf_parent_file_name,
            hdf_parent_group_name=f"{self.hdf_parent_group_name}/{name}",
            read_only=self.read_only,
            truncate=self.truncate,
        )
        for key, value in new_dict.items():
            new_group.__setattr__(key, value)
        if is_pd_dataframe:
            object.__setattr__(new_group, "_dtype", "dataframe")
        object.__setattr__(self, "_shape", self._shape + 1)
        return new_group

    def append(self, data):
        if isinstance(self.dtype, str):
            if self.dtype == "dataframe":
                for column_name in self:
                    array.append(data[column_name])
            else:
                raise NotImplementedError()
        else:
            with h5py.File(self.hdf_parent_file_name, "a") as hdf_file:
                hdf_object = hdf_file[self.hdf_parent_group_name]
                new_shape = tuple([i + j for i, j in zip(self.shape, data.shape)])
                hdf_object.resize(new_shape)
                hdf_object[self.shape[0]: self.shape[0] + data.shape[0]] = data
                object.__setattr__(self, "_shape", new_shape)

    def __getitem__(self, keys):
        if not isinstance(self.dtype, str):
            with h5py.File(self.hdf_parent_file_name, "r") as hdf_file:
                return hdf_file[self.hdf_parent_group_name][keys]
        elif self.dtype == "dataframe":
            with h5py.File(self.hdf_parent_file_name, "r") as hdf_file:
                hdf_object = hdf_file[self.hdf_parent_group_name]
                arrays = {}
                for name in hdf_object:
                    if isinstance(hdf_object[name], h5py.Dataset):
                        arrays[name] = hdf_object[name]
                return pd.DataFrame(
                    {
                        name: array[keys] for name, array in arrays.items()
                    }
                )
        elif self.dtype == "group":
            with h5py.File(self.hdf_parent_file_name, "r") as hdf_file:
                hdf_object = hdf_file[self.hdf_parent_group_name]
                if keys is Ellipsis:
                    return {
                        name: self.__getattribute__(name) for name in hdf_object
                    }
                elif keys not in hdf_object:
                    raise KeyError(
                        f"No object with {keys} available in this group"
                    )
                return self.__getattribute__(keys)
            return object.self.__dict__[keys]  # TODO might be to generic?
        else:
            raise KeyError("Dtype not understood")


class HDF_File(HDF_Object_Wrapper):

    def __init__(
        self,
        hdf_parent_file_name: str,
        *,
        read_only: bool = True,
        truncate: bool = False,
        delete_existing: bool = False,
    ):
        if delete_existing:
            mode = "w"
        else:
            mode = "a"
        with h5py.File(hdf_parent_file_name, mode) as hdf_file:
            pass
        super().__init__(
            hdf_parent_file_name=hdf_parent_file_name,
            hdf_parent_group_name="/",
            read_only=read_only,
            truncate=truncate,
        )